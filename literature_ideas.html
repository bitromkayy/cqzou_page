<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Literature & Ideas - ZOU CHENGQI Kay</title>
    <style>
        /* Inherit some styles from the main page for consistency */
        body {
            font-family: 'Segoe UI', Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f7f6;
            color: #333;
        }

        .container {
            max-width: 960px;
            margin: 20px auto;
            padding: 20px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);
        }

        header {
            text-align: center;
            padding: 30px 20px;
            background-color: #34495e; /* Consistent with main page nav bar */
            color: #ecf0f1;
            border-radius: 8px 8px 0 0;
            margin-bottom: 20px;
        }

        header h1 {
            margin: 0;
            font-size: 2.5em;
            color: #ecf0f1;
        }

        nav {
            background-color: #2c3e50; /* Slightly darker than header */
            padding: 10px 0;
            text-align: center;
            border-radius: 0 0 8px 8px;
            margin-bottom: 20px;
        }

        nav a {
            color: #ecf0f1;
            text-decoration: none;
            padding: 10px 20px;
            display: inline-block;
            transition: background-color 0.3s ease;
        }

        nav a:hover {
            background-color: #34495e;
            border-radius: 4px;
        }

        section {
            margin-bottom: 30px;
            padding: 20px;
            border: 1px solid #eee;
            border-radius: 6px;
            background-color: #fafafa;
        }

        h2 {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            margin-top: 0;
            margin-bottom: 20px;
        }

        h3 {
            color: #3498db;
            margin-top: 25px;
            margin-bottom: 10px;
        }

        p {
            margin-bottom: 15px;
            color: #555;
        }

        ul {
            list-style: disc;
            margin-left: 20px;
            color: #555;
        }

        ul li {
            margin-bottom: 8px;
        }

        footer {
            text-align: center;
            padding: 20px;
            margin-top: 30px;
            color: #777;
            font-size: 0.9em;
            border-top: 1px solid #eee;
        }
    </style>
</head>
<body>
    <header>
        <h1>Literature & Ideas</h1>
    </header>

    <nav>
        <a href="index.html">Back to Main Page</a>
    
    </nav>

    <div class="container">
        <section id="literature">
            <h2>My Literature Readings and Insights</h2>
            <p><strong> Living Document - Actively Updated</strong> [Last Snapshot: 2025/11/27]</p>
            <p>Neuroengineering is a highly interdisciplinary field that encompasses neuroscience, material science, imaging system design, machine learning, interpretable deep learning, and signal processing with feature extraction. To gain a deeper understanding of what I'm researching, I like reading papers that propose novel and interesting research perspectives and system architecture design for inspirations. Here I document some literature I've read and write down my thoughts during the reviewing. They are organized according to their research fields. </p>






            <h3>Neural Signal Decoding and Signal Processing</h3>
            <ul>
                <li>
                    <strong>“Deep learning for neural decoding in motor cortex” by Fangyu Liu et al.:</strong>
                    DOI: <a href="https://doi.org/10.1088/1741-2552/ac8fb5">10.1088/1741-2552/ac8fb5</a>
                    <br><small><strong>Notes: 1. </strong>How to compare deep learning model and human-generated simple hypothesis-driven model: if a human-generated simple hypothesis-driven model is less accurate than a deep learning model in the same task, the hypothesis-driven model likely has failed to capture important principles</small>
                    <br><small><strong>2. </strong> conclude 4 input feature normalization methods</small>
                    <br><small><strong>3. 5 * 2cv test: </strong> a statistical test to infer the statistical significance of differences in decoding performance among different models within a session</small>
                    <br><small><strong>4. </strong>use SHAP for interpretability analysis. The larger the absolute SHAP value, the more important the feature is</small>
                    <br><small><strong>5. </strong>ANN:use all inputs to process an output; LSTM: sequentially fed inputs to produce outputs</small>
                    <br><small><strong>6. </strong>For concurrent decoding (decode the position of the forelimb movement at that time), ANN (powerful non-linear-fitting capacity) > LSTM > Conventional ML models </small>
                    <br><small><strong>7. </strong>107 ms preceding time interval carries significant movement-related informations</small>
                    <br><small><strong>8. Spatiotemporal decoding: </strong>reconstruct images: each neuron is represented as a dot positioned at its center of mass and the brightness of the colered dot indicated the activity level of the corresponding neuron. The connectivity between a pair of neurons is represented by the thickness of the line connecting the two dots.</small>
                    <br><small><strong>9. </strong>Identity mapping by short connections to fix the shattered gradient problem (a significant challenge in deep learning where the gradient signal cannot effectively propagate backward through certain layers or operations during the backpropagation process)</small>
                    <br><small><strong>My Insight: 1. </strong>This work provides us a complete framework to decode neural signals from model design, data processing, data reconstruct to model performance evaluation, model comparison, interpretability analysis, and sensitivity analysis</small>
                    <br><small><strong>My Insight: 2. </strong>We may try to use GCN to substitute CNN because it can capture more spitial informations of neural signals</small>
                    <br><small><strong></strong></small>
                
                </li>


                <li>
                    <strong>“A Real-Time Framework for EEG Signal Decoding With Graph Neural Networks and Reinforcement Learning” by Htoo Wai Aung et al.:</strong>
                    DOI: <a href="https://doi.org/10.1109/TNNLS.2025.3558171">10.1109/TNNLS.2025.3558171</a>
                    <br><small><strong>Notes: 1. </strong>two primary categories of GCNs: spatial and spectral methods</small>
                    <br><small><strong>2. </strong>EEG_GLT can be used to optimize the adjacency matrix by calculating in different density levels (DOTA in adj_matrix construction)</small>
                    <br><small><strong>3. </strong>design a novel model architecture EEG_RL-Net, which is a combination of GNNs and RL, to classify EEG MI time point signals</small>
                    
                    
                    <br><small><strong>My Insight: 1. </strong>For strengthen the stability and improve accuracy, we can integrate RL into our deep learning model for neural decoding</small>
                
                    <br><small><strong></strong></small>
                </li>

                <li>
                    <strong>“The structural-functional-connectivity coupling of the aging brain” by Hui Zhang et al.:</strong>
                    DOI: <a href="https://doi.org/10.1007/s11357-024-01106-2">10.1007/s11357-024-01106-2</a>
                    <br><small><strong>Notes: 1. </strong>Structural connectivity matrix (SC): by counting the number of streamlines between all pairs of brain parcels. (DTI)</small>
                    <br><small><strong>2. </strong>Functional connectivity matrix (FC): by calculating the correlation coefficients between all pairs of brain parcels. (Resting-state fMRI)</small>
               
                    <br><small><strong>3. </strong>Structural connectivity matrix (SC): by counting the number of streamlines between all pairs of brain parcels. (DTI)</small>
                    <br><small><strong>3. </strong>Gordon's 12 functional brain clusters - a prior modules</small>
                    <br><small><strong>4. </strong>Structural-Functional-Connectivity Coupling (SFC): by calculating the Spearman-rank correlation coefficients between SC and FC matrix</small>
                    <br><small><strong>Intra-network SFC: </strong>SC and FC from the same functional brain clusters</small>
                    <br><small><strong>Inter-network SFC: </strong>SC and FC from different functional brain clusters</small>
                    <br><small><strong>My Insight: 1. </strong>For this work, we can train a multigraph GNN to carry out a regression task with different pathological, physiological, and other index as labels (e.g., age, edu, SVD score, and so on). 
                        We may construct graphs in which the nodes represent Gordon's 12 functional brain clusters. The edges correspond to the functional (FC) and structural (SC) connectivity between them, with the option to include SFC. For each node, its feature was defined as the sum of the corresponding column in the SC and FC matrices. 
                        For each edge, its feature was the direct connectivity value from these matrices. After the model training and validation, we can identify which functional brain clusters and which SC and/or FC edges contribute most to that index by interpretability analysis using GNNExplainer. A statistical analysis will be carried out on the results of the interpretability analysis for structural-functional-connectivity coupling analysis.</small>

                    <br><small><strong></strong></small>
                    <br>
               
                </li>

                <li>
                    <strong>“Evaluating fMRI preprocessing pipelines” by S.C. Strother:</strong>
                    DOI: <a href="https://doi.org/10.1109/MEMB.2006.1607667">10.1109/MEMB.2006.1607667</a>
                    <br><small><strong>Notes: 1. Cost function: </strong>measure the similarity of image volume in a time series to a reference volume </small>
                    <br><small><strong>2. </strong>Interpolation: Tradeoff between residual interpolation errors and speed</small>
                    <br><small><strong>3. </strong>Two preprocessing path (1): all-in-one analysis (data is completely preprocessed before data analysis); (2): summary statistic approach (individual-subject preprocessing and data analysis)</small>
                    <br><small><strong>My Insight: 1. </strong>This is a very useful guidelines for learning fMRI preprocessing</small>
                    <br><small><strong>My Insight: 2. </strong>Some software tools are listed in this paper for fMRI preprocessing</small>
                    <br><small><strong>My Insight: 3. </strong>For any preprocessing of signals including fMRI, we need to carry out Quality Control to visually assess the result of preprocessing steps to ensure the correctness of our preprocessing methods</small>
               
                    <br><small><strong></strong></small>
               
                </li>
                </li>






            </ul>


            <h3>Interpretable Deep Learning Architecture</h3>
            <ul>
                <li>
                    <strong>“BrainGNN: Interpretable Brain Graph Neural Network for fMRI Analysis” by Xiaoxiao Li et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.media.2021.102233">10.1016/j.media.2021.102233</a>
                    <br><small><strong>Notes 1: </strong>Graph Nodes: ROIs; Graph Edges: Connectivity between two ROIs</small>
                    <br><small><strong>2: brainGNN Architecture: </strong>graph input -> ROI-aware Graph Convolution Layer 1 (Ra-GConv 1) -> Pooling Layer 1 -> Ra-GConv 2 -> Pooling Layer 2 -> Readout Layer (Global Pooling Layer and Concatenate) -> MLP -> Classes</small>
                    <br><small><strong>3: Ra-GConv Layer: </strong>Soft Community Assignment -> Conditional Kernel Embedding -> Aggregate Node Information from Neighbors -> Update Node Representation</small>
                    
                    <br><small><strong>4: ROI Pooling Layer: </strong>Start from node embedding from Ra-GConv -> Projectiong On Pooling Vector -> Node Score Assignment -> Keep High-Score Nodes</small>
                
                    <br><small><strong>5: </strong>Location information is represented by one-hot encoding because the nodes in the brain are aligned well</small>
                
                    <br><small><strong>6: Concatenation: </strong>z_l = mean H_l || max H_l , z = z_1 || z_2 || ... || z_l</small>
                    <br><small><strong>7: Loss Function: </strong>Cross Entropy Loss + Unit Loss (to avoid indentifiability problem, i.e. the multiple parameters generate the same distribution of the observed data) + Group-level Consistency Loss (GLC Loss) (to force GNN to select similar ROIs in a R-pool layer for different input instances) + TopK Pooling Loss (TKP Loss) (to encourage reasonable node selection: selected: 1; unselected: 0)</small>
                    <br><small><strong>My Insight: 1. </strong>The work provides us a framework to construct our brain neural signals as graphs and use an interpretable BRAINGNN to predict some index</small>
                
                    <br><small><strong>My Insight: 2. </strong>Position is important because Ra-GConv will use position information to learn a customized kernel (weight matrix) for convolution</small>
             
                    <br><small><strong></strong></small>
                </li>

                <li>
                    <strong>“Interpretable deep learning for deconvolutional analysis of neural signals” by Bahareh Tolooshams et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.neuron.2025.02.006">10.1016/j.neuron.2025.02.006</a>
                    <br><small><strong>Notes 1: </strong>Why we need DUNL: to decompose neural activity into overlapping and nonoverlapping components that capture heterogeneity in the population</small>
                    <br><small><strong>2: </strong>The parameters are shared between encoder and decoder</small>
                    <br><small><strong>3: </strong>The latend code: represent estimated stimulus onsets and strength of the neura; response to that stimulus</small>
                    <br><small><strong>4: </strong>The code we input is a mask for code support</small>
                    <br><small><strong>5: </strong>In this model, kernel H is the only parameter to be learnt</small>
                    <br><small><strong>My Insight: 1. </strong>In this framwork, we most important part is that by convolution, we can learn the underlying neural activity (code) by inputting a detectable neural signals. In true neural physiology, each one of these underlying neural activities (codes) can produce a series of detectable neural signals with different kernels. To make the model adapt to more realistic neural signals, we can propose a 2DDUNL based on DUNL, where a series of neural signals will be deconvoluted with different kernels to get the same neural activity code. By convoluting the code with different kernels, we can reconstruct the detectable neural signais.</small>
                    <br><small><strong>My Insight: 2. </strong>By designing a correlation loss, if we have real but non-sparse code, the DUNL can also learn the dense code.</small>

                    <br><small><strong></strong></small>
                </li>
                


                
                <li>
                    <strong>“KerGNNs: Interpretable Graph Neural Networks with Graph Kernels” by Aosong Feng et al.:</strong>
                    DOI: <a href="https://doi.org/10.1609/aaai.v36i6.20615">10.1609/aaai.v36i6.20615</a>
                    <br><small><strong>Notes: 1: </strong>KerGNN: integrate graph kernels into the message passing process of GNNs</small>
                    <br><small><strong>2: 3 steps to generate node embeddings for MPNNs: </strong>(1) receiving message from its neighbors; (2) aggregating messages; (3) updating its own features to encode the local information</small>
                    <br><small><strong>3: </strong>Problem: MPNNs are limited by WL (Weisfeiler-Lehman) kernels</small>
                    <br><small><strong>4: </strong>kerGNN: a sub-graph-based node aggregation algorithm</small>
                    <br><small><strong>5: </strong>Graph kernels are proposed to solve the problem of assessing the similarity between graphs</small>
                    <br><small><strong>6: </strong>Graph kernels: (1) simple node-pair kernel (2) random walk kernels (count the number of walk that two graphs have in common)</small>
                    <br><small><strong>7: </strong>For graphs without node features, we can use degree for substitution</small>
                    <br><small><strong>8: </strong>What is subgraph: the vertex-induced subgraph formed from a node and all its 1-hop neighbors</small>
                    <br><small><strong>9: </strong>How to carry out subgraph-based aggregation: extract subgraph -> compare against a set of learnable graph filters -> measure the topological similarity -> according to the similarity, update new node feature maps</small>
                    <br><small><strong>My Insight: 1. </strong>This architecture is meaningful and interpretable because it trains a set of visuallizable pattern templetes (graph filters), which are the features the model try to search in the input data.</small>
                
                    <br><small><strong>My Insight: 2. </strong>We can try to use KerGNN to carry out neural signal decoding tasks. For neural signals, the graph filters mean particular neural connectivity pattern which is related to pathological or psychological index we want to study. Beacuse we can directly visuallize the graph filters the model learnt, we do not need post-experimental interpretability analysis (e.g., using GNNExplainer).</small>
            
                    <br><small><strong></strong></small>
                </li>

                

            </ul>


            <h3>Deep Learning Application in Neuroengineering</h3>
            <ul>
                <li>
                    <strong>“Applications of interpretable deep learning in neuroimaging: A comprehensive review” by Lindsay Munroe et al.:</strong>
                    DOI: <a href="https://doi.org/10.1162/imag_a_00214">10.1162/imag_a_00214</a>
                    <br><small><strong>Notes: 1: </strong>General applications of DL in neuroimaging: segmentation, super-resolution, image synthesis, and classification</small>
                    <br><small><strong>2: </strong>Challenge of interpretable DL (iDL): difficult to assess the quality of explanations beacause the ground trues of the explanations are typically unavailable.</small>
                    <br><small><strong>3: Fidelity: </strong>the extent to which explanations reflect the inner working of the DL model -> feature-removal</small>
                    <br><small><strong>4: Robustness: </strong>the stability of the model explanations under different modelling conditions</small>
                    <br><small><strong>5: 2 main categories of iDL methods: </strong>post-hoc (reverse engineering, e.g. GNNExplainer, SHAP, ...) and intrinsic (incorporate interpretable components into model architecture while designing, e.g., DUNL and kerGNN) </small>
                    <br><small><strong>6: Post-huc methods: (1) </strong>Perturbation-based methods: alter input features and measure change of output. (Occlusion, Meaningful Perburbations, Local Interpretable Model-Agnostic Explanations (LIAE), Swap Test, Permutation Feature Importance). Advantages: easy to implement and understand; do not require network and gradient. Disadvantages: computationally intensive and time-consuming; distribution shift for change in input.</small>
                    <br><small><strong>(2) </strong>Gradient-based methods: compute the partial derivative of an output with respect to each input features. Need backpropagation. (Vanilla Gradient, Grad x Input, SmoothGrad, Integrated Gradients) Advantages: fast to run and easy to understand. Disadvantages: shattered gradients, saturation problem, gradient map is less able to discriminate between classes.</small>
                    <br><small><strong>(3) </strong>Backpropagation-based methods: apply rules to map the output score back to the input features to assign feature relevance. (Guided Backpropagation, Layer-wise Relevance Propagation (LRP), GNNExplainer).</small>
                    <br><small><strong>(4) </strong>Class activation maps: highlight image regions used by the final layer of a CNN to classify the input image. Gradient-Weighted Class Activation Maps (Grad-CAM): extent CAM to all CNNs to obviate the need for a GAP layer. Advantages: easy to implement and widely available. Disadvantages: heatmaps are coarse - low resolution because of upsampling.</small>
                    <br><small><strong>(5) </strong>Weight Analysis: analyze the weights of the trained network. (Network Dissection)</small>
                    <br><small><strong>7: Intrinsic methods: (1) </strong>Disentangled latent spaces: Input -> a learnable representation (latent space). (e.g. Autoencoder and Capsule Network) Advantages: provide some control for image generation to the end user. Disadvantages: the generative factors may not be inherently independent, by constraining the latent representations to must be independent, some information will lose. Come at the expense of performance. </small>

                    <br><small><strong>(2) </strong>Interpretable hybrid models and interpretable intermediate features: A hybrid model has two components: NN (neual network) + NN or NN + ML. The first NN is for processing intermediate feature representations, which can be understood by humans and act as model explanations. Advantages: can be designed so the intermediate features are suited for a particular application. Disadvantages: need careful design and take a long time to develop</small>
                    <br><small><strong>(3) </strong>Interpretable generative models: learn to generate modifications to the input image so that the modified image appears to belong to a different class. The modifications can be used as explanations. Advantages: capable of capturing more meaningful class-discriminative features. Disadvantages: high computational power needed and difficult to train</small>
                    <br><small><strong>(4) </strong>Deep structural causal models: estimate causal effects by simulating population-level interventions. Endogenous Variables + Exogenous or Noise Variables. Advantages: control for confounders. Disadvantages: should be constructed carefully from domain knowledge and impossible to obtain ground truth data.</small>
                    <br><small><strong>(5) </strong>Attention mechanisms: learn a heatmap over the inputs, features, ou channels of the neural network. Weight data to emphasise key features. 4 main types of attention: channel attention (assign a weight to each filter), spitial attention (extract important information in the image domain or across the spatial dimensions of a feature map), non-local attention (capture long-range dependencies by computing interactions between any two positions), and self attention (tokenization + QKV). Advantages: differentiable objective and easily trainable with gradient descent.</small>

                    <br><small><strong>My Insight: 1. </strong>This work can act as a guideline for us to design an interpretable model architecture and carry out interpretability analysis after model performance evaluation.</small>
                    <br><small><strong>My Insight: 2. </strong>In my opinion, designing a intrinsic interpretable model which is built upon our prior knowledge and physiological hypothesis is preferred beacause this model actually mimics the real physiological process in our brain (if the performance of the model is acceptable, we can use this interpretable model as a part of "silicon brain")</small>

                    <br><small><strong></strong></small>
                </li>

                <li>
                    <strong>“Interpretable deep learning: interpretation, interpretability, trustworthiness, and beyond” by Xuhong Li et al.:</strong>
                    DOI: <a href="https://doi.org/10.1007/s10115-022-01756-8">10.1007/s10115-022-01756-8</a>
                    <br><small><strong></strong></small>
                    <br><small><strong></strong></small>
                    <br><small><strong></strong></small>
                    <br><small><strong></strong></small>
                </li>

                <li>
                    <strong>“Dissociating language and thought in large language models” by Kyle Mahowald et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.tics.2024.01.011">10.1016/j.tics.2024.01.011</a>
                    <br><small><strong></strong></small>
                    <br><small><strong></strong></small>
                    <br><small><strong></strong></small>
                    <br><small><strong></strong></small>
                </li>


            </ul>



            <h3>Radiology and Imaging Technologies</h3>
            <ul>

                <li>
                    <strong>“Simultaneous EEG-fMRI for Functional Neurological Assessment” by Giulia Mele et al.:</strong>
                    DOI: <a href="https://doi.org/10.3389/fneur.2019.00848">10.3389/fneur.2019.00848</a>
                    <br><small><strong>Notes 1: </strong>Brain electrical activity is derived from the synchronizations of a pool of cortial neurons (pyramidal cells)</small>
                    <br><small><strong>2: </strong>the potentials that appear within the 100ms post stimulus are usually due to the nature of stimulus itself (artifact), while the subsequent components reflect the cognitive processes related to the perception of the stimulus</small>
                    <br><small><strong>3: </strong>BOLD is an indirect measure of neuronal activity</small>
                    <br><small><strong>4: </strong>fMRI: high spatial resolution; EEG: high temporal resolution</small>
                    <br><small><strong>5: </strong>Precautions in EEG-fMRI: (1) Gradient echo-echo planer protocol; (2) extensive safety testing with temperature sensors</small>
                    <br><small><strong>6: </strong>Simultaneous resting-state EEG-fMRI is fundamental for underling the variability of brain activity and above all to define the structures involved in the triggering EEG waves in resting state</small>
                    <br><small><strong>7: </strong>theta-alpha low frequency oscillations are linked to the functional activation of a network involving the hippocampus, the striatum, and the prefrontal cortex</small>
                    <br><small><strong>8: </strong>EEG-fMRI analysis methods: symmetric analysis (the simultaneous analysis of EEG and fMRI signal) and integrated analysis (use one signal to understand and validate another)</small>
                    <br><small><strong>My Insight: 1. </strong></small>For task-based simultaneous EEG-fMRI, we can use neuromodulation to stimulate a particular brain region and use simultaneous EEG-fMRI to monitor the brain response to the stimulation with high spatiotemporal resolution. This can help us understand the causal relationship between brain region function and cognitive process. i.e. We can build a simultaneous real time EEG-fMRI neurofeedback system
                    
                </li>

                <li>
                    <strong>“High temporal resolution functional MRI using parallel echo volumar imaging” by Cécile Rabrait MS et al.:</strong>
                    DOI: <a href="https://doi.org/10.1002/jmri.21329">10.1002/jmri.21329</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>


            </ul>

            <h3>Brain Computer Interface (hardware)</h3>
            <ul>
                <li>
                    <strong>“Real-time BCI system design to control arduino based speed controllable robot using EEG” by Swagata Das et al.:</strong>
                    DOI: <a href="https://doi.org/10.1007/978-981-13-3098-8">10.1007/978-981-13-3098-8</a>
                    <br><small><strong>Notes: </strong>This is a useful book to teach us how to build a BCI system to accomplish Arduino control from hardware prepration to software and AI implementation</small>
                </li>


            </ul>


            <h3>Brain Computer Interface (AI and software)</h3>
            <ul>
                <li>
                    <strong>“A Deep-Learning Empowered, Real-Time Processing Platform of fNIRS/DOT for Brain Computer Interfaces and Neurofeedback” by Yunjia Xia et al.:</strong>
                    DOI: <a href="https://doi.org/10.1109/TNSRE.2025.3553794">10.1109/TNSRE.2025.3553794</a>
                    <br><small><strong>Notes 1: </strong>Advantages of fNIRS over EEG: (1) higher spatial resolution; (2) potenital higher tolerance to motion artifacts</small>
                    <br><small><strong>2: </strong>Diffuse Optical Tomograph (DOT) employs an array of multiple near-infrared light sources and detectors at different source-detector separations - overlapping spatial sampling to reconstruct 3D images</small>
                
                    <br><small><strong>3: </strong>Challenges for fNIRS-DOT: (1) require a baseline, which is difficult to establish in real-time measurements; (2) real-time processing is hindered by the absence of prior information and delays</small>
                    <br><small><strong>4: </strong>typical fNIRS-DOT imaging pipeline: preprocessing - forward modeling - inverse problem solving</small>
                    <br><small><strong>My Insight 1: </strong>For real-time control of BCI, because of absence of baseline, pre-trained deep learning models for denoising and articate correction (e.g., Denoising autoencoder (DAE)) is an useful methods for real-time preprocessing</small>
                    <br><small><strong>My Insight 2: </strong>For real-time BCI, the biggest challenge we face is delay. How to decrease the delay into an acceptable range is an important issue we need to consider. To minize the delay while maintaining the accuracy of BCI, pre-trained and real-time fine-tunable (just before the using of BCI) deep learning system is need to be explored.</small>

                </li>
                
                <li>
                    <strong>“EEG-based brain-computer interface enables real-time robotic hand control at individual finger level” by Yidan Ding et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41467-025-61064-x">10.1038/s41467-025-61064-x</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>
                
                <li>
                    <strong>“A review of critical challenges in MI-BCI: From conventional to deep learning methods” by Zahra Khademi et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.jneumeth.2022.109736">10.1016/j.jneumeth.2022.109736</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>

                <li>
                    <strong>“Advancing BCI with a transformer-based model for motor imagery classification” by Wangdan Liao et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41598-025-06364-4">10.1038/s41598-025-06364-4</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>


             
            
            </ul>

    

            <h3>Neuroscience (Anatomy and Physiology)</h3>
            <ul>


                <li>
                    <strong>“Invariant neural dynamics drive commands to control different movements” by Vivek R. Athalye et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.cub.2023.06.027">10.1016/j.cub.2023.06.027</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>
            </ul>


            <h3>Computational Neuroscience (Computational Models, For Simulation Data Acquisition)</h3>
            <ul>
                <li>
                    <strong>“Benchmarking Deep Jansen-Rit Parameter Inference: An in Silico Study” by Tilwani, Deepa and O'Reilly, Christian:</strong>
                    Link: <a href="https://arxiv.org/html/2406.05002v1">https://arxiv.org/html/2406.05002v1</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>


                <li>
                    <strong>“EEG–fMRI Bayesian framework for neural activity estimation: a simulation study” by Pierpaolo Croce et al.:</strong>
                    DOI: <a href="https://doi.org/10.1088/1741-2560/13/6/066017">10.1088/1741-2560/13/6/066017</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --> </strong></small>
                </li>


            </ul>

            <h3>Materials</h3>
            <ul>

                <li>
                    <strong>“Properties and Applications of PDMS for Biomedical Engineering: A Review” by Ines Miranda et al.:</strong>
                    DOI: <a href="https://doi.org/10.3390/jfb13010002">10.3390/jfb13010002</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>


                <li>
                    <strong>“Soft, conformal PDMS-based ECoG electrode array for long-term in vivo applications” by Hyunmin Moon et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.snb.2023.135099">10.1016/j.snb.2023.135099</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>

            </ul>


            <h3>Animal Neuroscience Experiment and Experimental Paradigm Design</h3>
            <ul>
                <li>
                    <strong>“Neural Circuits Underlying Visually Evoked Escapes in Larval Zebrafish” by Timothy W. Dunn et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.neuron.2015.12.021">10.1016/j.neuron.2015.12.021</a>
                    <br><small><!-- [Notes to be added in the next update] --><strong></strong></small>
                </li>
                


                <li>
                    <strong>“Guidelines for the care and use of mammals in neuroscience and behavioral research” by National Research Council (US) Committee on Guidelines for the Use of Animals in Neuroscience and Behavioral Research
:</strong>
                    DOI: <a href="https://doi.org/10.17226/10732">10.17226/10732</a>
                    <br><small><strong>Notes: </strong>This guidelines provides us a systematic, ethical, and scientifically rigorous framework for designing neuroscience animal experiments</small>
                </li>
                


            </ul>




            

        </section>



        <section id="dataset">
            <h2>Open-source Dataset</h2>
            <p>Here are some open-source datasets that I find particularly useful or interesting in my research:</p>

            <h3>EEG</h3>
            <ul>

                <li>
                    <strong>Publication: “A multi-day and high-quality EEG dataset for motor imagery brain-computer interface” by Banghua Yang et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41597-025-04826-y">10.1038/s41597-025-04826-y</a>
                    <strong>Link: <a href="https://plus.figshare.com/articles/dataset/Brain_Computer_Interface_Motor_Imagery-EEG_Dataset/22671172?file=51001884">https://plus.figshare.com/articles/dataset/Brain_Computer_Interface_Motor_Imagery-EEG_Dataset/22671172?file=51001884</a>
                    <br><small><strong>Notes: </strong>A Motor-Imagery-(MI)-related EEG dataset, which can be used for training and testing of MI-based BCI deep learning models.</small>
                </li>


            </ul>

            <h3>fMRI</h3>
            <ul>

                <li>
                    <strong>Publication: “An fMRI dataset for investigating language control and cognitive control in bilinguals” by Tingting Guo et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41597-025-05245-9">10.1038/s41597-025-05245-9</a>
                    <strong>Link: <a href="https://openneuro.org/datasets/ds005455/versions/1.1.5">https://openneuro.org/datasets/ds005455/versions/1.1.5</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>


                <li>
                    <strong>Publication: “A natural language fMRI dataset for voxelwise encoding models” by Amanda LeBel et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41597-023-02437-z">10.1038/s41597-023-02437-z</a>
                    <strong>Link: <a href="https://openneuro.org/datasets/ds003020/versions/2.0.0">https://openneuro.org/datasets/ds003020/versions/2.0.0</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>


                <li>
                    <strong>Publication: “An fMRI Dataset for Concept Representation with Semantic Feature Annotations” by Shaonan Wang et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41597-022-01840-2">10.1038/s41597-022-01840-2</a>
                    <strong>Link: <a href="https://openneuro.org/datasets/ds004301">https://openneuro.org/datasets/ds004301</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>




            </ul>


            <h3>Simultaneous EEG-fMRI</h3>
            <ul>
                <li>
                    <strong>Publication: “An open-access dataset using simultaneous EEG-fMRI” by Telesford QK et al.:</strong>
                    DOI: <a href="https://doi.org/10.1101/2022.11.23.517540">10.1016/j.neuroimage.2021.118591</a>
                    <strong>Link: <a href="https://fcon_1000.projects.nitrc.org/indi/retro/nat_view.html">https://fcon_1000.projects.nitrc.org/indi/retro/nat_view.html</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>


            </ul>

            <h3>ECoG</h3>
            <ul>

                <li>
                    <strong>Publication: “The “Podcast” ECoG dataset for modeling neural activity during natural language comprehension” by Zaid Zada et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41597-025-05462-2">10.1038/s41597-025-05462-2</a>
                    <strong>Link: <a href="https://openneuro.org/datasets/ds005574/versions/1.0.2">https://openneuro.org/datasets/ds005574/versions/1.0.2</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>

            </ul>

            <h3>fNIRS</h3>
            <ul>


            </ul>

            <h3>DWI</h3>
            <ul>


            </ul>
        
        
        </section>



        <section id="tools">
            <h2>Open-source Tools</h2>
            <p>Here I list some useful tools or websites that are useful for neural signal processing:</p>

            <h3>EEGLAB</h3>
            <ul>
                <li>
                    <strong>Link: <a href="https://sccn.ucsd.edu/eeglab/">https://sccn.ucsd.edu/eeglab/</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>
            </ul>


            <h3>BRAINFLOW</h3>
            <ul>
                <li>
                    <strong>Link: <a href="https://brainflow.org/">https://brainflow.org/</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>
            </ul>

            <h3>BRAINSTORM</h3>
            <ul>
                <li>
                    <strong>Link: <a href="https://neuroimage.usc.edu/brainstorm/Introduction">https://neuroimage.usc.edu/brainstorm/Introduction</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>
            </ul>

            <h3>rsHRF</h3>
            <ul>
                <li>
                    <strong>“rsHRF: A toolbox for resting-state HRF estimation and deconvolution” by Guo-Rong Wu et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.neuroimage.2021.118591">10.1016/j.neuroimage.2021.118591</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>
            </ul>

            <h3>OpenBCI</h3>
            <ul>
                <li>
                    <strong>Link: <a href="https://openbci.com/">https://openbci.com/</a>
                    <br><small><strong><!-- [Notes to be added in the next update] --></strong></small>
                </li>
            </ul>

        
        
        </section>

        <section id="ideas">
            <h2>Sparks of Thought</h2>
            <p> I believe technology's most meaningful progress is guided by personal inspiration. Here, I summarize some divergent thoughts during my research and literature reading:</p>

            <h3></h3>
            <ul>



            </ul>

            <h3></h3>
            <ul>




            </ul>
            <!-- You can write about questions you're pondering or your views on a societal phenomenon -->
        </section>
    </div>

    <footer>
        <p>&copy; 2025 ZOU CHENGQI Kay. All rights reserved.</p>
        <p>Back to <a href="index.html">Main Page</a></p>
    </footer>
</body>
</html>
