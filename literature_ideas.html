<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Literature & Ideas - [Your Name]</title>
    <style>
        /* Inherit some styles from the main page for consistency */
        body {
            font-family: 'Segoe UI', Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f7f6;
            color: #333;
        }

        .container {
            max-width: 960px;
            margin: 20px auto;
            padding: 20px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);
        }

        header {
            text-align: center;
            padding: 30px 20px;
            background-color: #34495e; /* Consistent with main page nav bar */
            color: #ecf0f1;
            border-radius: 8px 8px 0 0;
            margin-bottom: 20px;
        }

        header h1 {
            margin: 0;
            font-size: 2.5em;
            color: #ecf0f1;
        }

        nav {
            background-color: #2c3e50; /* Slightly darker than header */
            padding: 10px 0;
            text-align: center;
            border-radius: 0 0 8px 8px;
            margin-bottom: 20px;
        }

        nav a {
            color: #ecf0f1;
            text-decoration: none;
            padding: 10px 20px;
            display: inline-block;
            transition: background-color 0.3s ease;
        }

        nav a:hover {
            background-color: #34495e;
            border-radius: 4px;
        }

        section {
            margin-bottom: 30px;
            padding: 20px;
            border: 1px solid #eee;
            border-radius: 6px;
            background-color: #fafafa;
        }

        h2 {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            margin-top: 0;
            margin-bottom: 20px;
        }

        h3 {
            color: #3498db;
            margin-top: 25px;
            margin-bottom: 10px;
        }

        p {
            margin-bottom: 15px;
            color: #555;
        }

        ul {
            list-style: disc;
            margin-left: 20px;
            color: #555;
        }

        ul li {
            margin-bottom: 8px;
        }

        footer {
            text-align: center;
            padding: 20px;
            margin-top: 30px;
            color: #777;
            font-size: 0.9em;
            border-top: 1px solid #eee;
        }
    </style>
</head>
<body>
    <header>
        <h1>Literature & Ideas</h1>
    </header>

    <nav>
        <a href="my_page.html">Back to Main Page</a>
        <!-- You can add more sub-page navigation links here -->
    </nav>

    <div class="container">
        <section id="literature">
            <h2>My Literature Readings and Comments</h2>
            <p>Neuroengineering is a highly interdisciplinary field that encompasses neuroscience, materials science, imaging system design, machine learning, interpretable deep learning, and signal processing with feature extraction. To gain a deeper understanding of what I'm researching, I like reading papers that propose novel and interesting research perspectives and system architecture design for inspirations. Here I document some literature I've read and records my thoughts during the reviewing. There are organized according to their research fields. </p>






            <h3>Neural Signal Decoding and Signal Processing</h3>
            <ul>
                <li>
                    <strong>“Deep learning for neural decoding in motor cortex” by Fangyu Liu et al.:</strong>
                    DOI: <a href="https://doi.org/10.1109/TNNLS.2025.3558171">10.1109/TNNLS.2025.3558171</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>


                <li>
                    <strong>“A Real-Time Framework for EEG Signal Decoding With Graph Neural Networks and Reinforcement Learning” by Htoo Wai Aung et al.:</strong>
                    DOI: <a href="https://doi.org/10.1088/1741-2552/ac8fb5">10.1088/1741-2552/ac8fb5</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>

                <li>
                    <strong>“The structural-functional-connectivity coupling of the aging brain” by Hui Zhang et al.:</strong>
                    DOI: <a href="https://doi.org/10.1007/s11357-024-01106-2">10.1007/s11357-024-01106-2</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>

                <li>
                    <strong>“Evaluating fMRI preprocessing pipelines” by S.C. Strother:</strong>
                    DOI: <a href="https://doi.org/10.1109/MEMB.2006.1607667">10.1109/MEMB.2006.1607667</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>






            </ul>


            <h3>Interpretable Deep Learning Architecture</h3>
            <ul>
                <li>
                    <strong>“BrainGNN: Interpretable Brain Graph Neural Network for fMRI Analysis” by Xiaoxiao Li et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.media.2021.102233">10.1016/j.media.2021.102233</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>

                <li>
                    <strong>“Interpretable deep learning for deconvolutional analysis of neural signals” by Bahareh Tolooshams et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.neuron.2025.02.006">10.1016/j.neuron.2025.02.006</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
                


                
                <li>
                    <strong>“KerGNNs: Interpretable Graph Neural Networks with Graph Kernels” by Aosong Feng et al.:</strong>
                    DOI: <a href="https://doi.org/10.1609/aaai.v36i6.20615">10.1609/aaai.v36i6.20615</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>

                

            </ul>


            <h3>Deep Learning Application in Neuroengineering</h3>
            <ul>
                <li>
                    <strong>“Applications of interpretable deep learning in neuroimaging: A comprehensive review” by Lindsay Munroe et al.:</strong>
                    DOI: <a href="https://doi.org/10.1162/imag_a_00214">10.1162/imag_a_00214</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>

                <li>
                    <strong>“Interpretable deep learning: interpretation, interpretability, trustworthiness, and beyond” by Xuhong Li et al.:</strong>
                    DOI: <a href="https://doi.org/10.1007/s10115-022-01756-8">10.1007/s10115-022-01756-8</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>

                <li>
                    <strong>“Dissociating language and thought in large language models” by Kyle Mahowald et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.tics.2024.01.011">10.1016/j.tics.2024.01.011</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>


            </ul>



            <h3>Radiology and Imaging Technologies</h3>
            <ul>

                <li>
                    <strong>“Simultaneous EEG-fMRI for Functional Neurological Assessment” by Giulia Mele et al.:</strong>
                    DOI: <a href="https://doi.org/10.3389/fneur.2019.00848">10.3389/fneur.2019.00848</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>

                <li>
                    <strong>“High temporal resolution functional MRI using parallel echo volumar imaging” by Cécile Rabrait MS et al.:</strong>
                    DOI: <a href="https://doi.org/10.1002/jmri.21329">10.1002/jmri.21329</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>


            </ul>

            <h3>Brain Computer Interface (hardware)</h3>
            <ul>
                <li>
                    <strong>“Real-time BCI system design to control arduino based speed controllable robot using EEG” by Swagata Das et al.:</strong>
                    DOI: <a href="https://doi.org/10.1007/978-981-13-3098-8">10.1007/978-981-13-3098-8</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>

                <li>
                    <strong>“Brain-Computer Interfaces Using Electrocorticographic Signals” by Gerwin Schalk and Eric C. Leuthardt:</strong>
                    DOI: <a href="https://doi.org/10.1109/RBME.2011.2172408">10.1109/RBME.2011.2172408</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>

            </ul>


            <h3>Brain Computer Interface (AI and software)</h3>
            <ul>
                <li>
                    <strong>“A Deep-Learning Empowered, Real-Time Processing Platform of fNIRS/DOT for Brain Computer Interfaces and Neurofeedback” by Yunjia Xia et al.:</strong>
                    DOI: <a href="https://doi.org/10.1109/TNSRE.2025.3553794">10.1109/TNSRE.2025.3553794</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
                
                <li>
                    <strong>“EEG-based brain-computer interface enables real-time robotic hand control at individual finger level” by Yidan Ding et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41467-025-61064-x">10.1038/s41467-025-61064-x</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
                
                <li>
                    <strong>“A review of critical challenges in MI-BCI: From conventional to deep learning methods” by Zahra Khademi et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.jneumeth.2022.109736">10.1016/j.jneumeth.2022.109736</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
             
            
            </ul>

    

            <h3>Neuroscience (Anatomy and Physiology)</h3>
            <ul>


                <li>
                    <strong>“Invariant neural dynamics drive commands to control different movements” by Vivek R. Athalye et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.cub.2023.06.027">10.1016/j.cub.2023.06.027</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
            </ul>


            <h3>Computational Neuroscience (Computational Models, For Simulation Data Acquisition)</h3>
            <ul>
                <li>
                    <strong>“Benchmarking Deep Jansen-Rit Parameter Inference: An in Silico Study” by Tilwani, Deepa and O'Reilly, Christian:</strong>
                    Link: <a href="https://arxiv.org/html/2406.05002v1">https://arxiv.org/html/2406.05002v1</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>


                <li>
                    <strong>“EEG–fMRI Bayesian framework for neural activity estimation: a simulation study” by Pierpaolo Croce et al.:</strong>
                    DOI: <a href="https://doi.org/10.1088/1741-2560/13/6/066017">10.1088/1741-2560/13/6/066017</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>


            </ul>

            <h3>Materials</h3>
            <ul>

                <li>
                    <strong>“Properties and Applications of PDMS for Biomedical Engineering: A Review” by Ines Miranda et al.:</strong>
                    DOI: <a href="https://doi.org/10.3390/jfb13010002">10.3390/jfb13010002</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>


                <li>
                    <strong>“Soft, conformal PDMS-based ECoG electrode array for long-term in vivo applications” by Hyunmin Moon et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.snb.2023.135099">10.1016/j.snb.2023.135099</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>

            </ul>


            <h3>Animal Neuroscience Experiment and Experimental Paradigm Design</h3>
            <ul>
                <li>
                    <strong>“Neural Circuits Underlying Visually Evoked Escapes in Larval Zebrafish” by Timothy W. Dunn et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.neuron.2015.12.021">10.1016/j.neuron.2015.12.021</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
                

                <li>
                    <strong>“Selection, evolution of behavior and animal models in behavioral neuroscience” by Stefano Parmigiani et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/S0149-7634(99)00029-9">10.1016/S0149-7634(99)00029-9</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>


                <li>
                    <strong>“Guidelines for the care and use of mammals in neuroscience and behavioral research” by National Research Council (US) Committee on Guidelines for the Use of Animals in Neuroscience and Behavioral Research
:</strong>
                    DOI: <a href="https://doi.org/10.17226/10732">10.17226/10732</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
                


            </ul>




            

        </section>



        <section id="dataset">
            <h2>Open-sourse Dataset</h2>
            <p>Here are some open-source datasets that I find particularly useful or interesting in my research:</p>

            <h3>EEG</h3>
            <ul>

                <li>
                    <strong>Publication: “A multi-day and high-quality EEG dataset for motor imagery brain-computer interface” by Banghua Yang et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41597-025-04826-y">10.1038/s41597-025-04826-y</a>
                    <strong>Link: <a href="https://plus.figshare.com/articles/dataset/Brain_Computer_Interface_Motor_Imagery-EEG_Dataset/22671172?file=51001884">https://plus.figshare.com/articles/dataset/Brain_Computer_Interface_Motor_Imagery-EEG_Dataset/22671172?file=51001884</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>


            </ul>

            <h3>fMRI</h3>
            <ul>

                <li>
                    <strong>Publication: “An fMRI dataset for investigating language control and cognitive control in bilinguals” by Tingting Guo et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41597-025-05245-9">10.1038/s41597-025-05245-9</a>
                    <strong>Link: <a href="https://openneuro.org/datasets/ds005455/versions/1.1.5">https://openneuro.org/datasets/ds005455/versions/1.1.5</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>


                <li>
                    <strong>Publication: “A natural language fMRI dataset for voxelwise encoding models” by Amanda LeBel et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41597-023-02437-z">10.1038/s41597-023-02437-z</a>
                    <strong>Link: <a href="https://openneuro.org/datasets/ds003020/versions/2.0.0">https://openneuro.org/datasets/ds003020/versions/2.0.0</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>


                <li>
                    <strong>Publication: “An fMRI Dataset for Concept Representation with Semantic Feature Annotations” by Shaonan Wang et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41597-022-01840-2">10.1038/s41597-022-01840-2</a>
                    <strong>Link: <a href="https://openneuro.org/datasets/ds004301">https://openneuro.org/datasets/ds004301</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>




            </ul>


            <h3>Simultaneous EEG-fMRI</h3>
            <ul>
                <li>
                    <strong>Publication: “An open-access dataset using simultaneous EEG-fMRI” by Telesford QK et al.:</strong>
                    DOI: <a href="https://doi.org/10.1101/2022.11.23.517540">10.1016/j.neuroimage.2021.118591</a>
                    <strong>Link: <a href="https://fcon_1000.projects.nitrc.org/indi/retro/nat_view.html">https://fcon_1000.projects.nitrc.org/indi/retro/nat_view.html</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>


            </ul>

            <h3>ECoG</h3>
            <ul>

                <li>
                    <strong>Publication: “The “Podcast” ECoG dataset for modeling neural activity during natural language comprehension” by Zaid Zada et al.:</strong>
                    DOI: <a href="https://doi.org/10.1038/s41597-025-05462-2">10.1038/s41597-025-05462-2</a>
                    <strong>Link: <a href="https://openneuro.org/datasets/ds005574/versions/1.0.2">https://openneuro.org/datasets/ds005574/versions/1.0.2</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>

            </ul>

            <h3>fNIRS</h3>
            <ul>


            </ul>

            <h3>DWI</h3>
            <ul>


            </ul>
        
        
        </section>



        <section id="tools">
            <h2>Open-sourse Dataset</h2>
            <p>Here I list some useful tools or websites that are useful for neural signal processing:</p>

            <h3>EEGLAB</h3>
            <ul>
                <li>
                    <strong>Link: <a href="https://sccn.ucsd.edu/eeglab/">https://sccn.ucsd.edu/eeglab/</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
            </ul>


            <h3>BRAINFLOW</h3>
            <ul>
                <li>
                    <strong>Link: <a href="https://brainflow.org/">https://brainflow.org/</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
            </ul>

            <h3>BRAINSTORM</h3>
            <ul>
                <li>
                    <strong>Link: <a href="https://neuroimage.usc.edu/brainstorm/Introduction">https://neuroimage.usc.edu/brainstorm/Introduction</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
            </ul>

            <h3>rsHRF</h3>
            <ul>
                <li>
                    <strong>“rsHRF: A toolbox for resting-state HRF estimation and deconvolution” by Guo-Rong Wu et al.:</strong>
                    DOI: <a href="https://doi.org/10.1016/j.neuroimage.2021.118591">10.1016/j.neuroimage.2021.118591</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
            </ul>

            <h3>OpenBCI</h3>
            <ul>
                <li>
                    <strong>Link: <a href="https://openbci.com/">https://openbci.com/</a>
                    <br><small><strong>Notes:</strong>a</small>
                </li>
            </ul>

        
        
        </section>

        <section id="ideas">
            <h2>Sparks of Thought</h2>
            <p> I believe technology's most meaningful progress is guided by personal inspiration. Here, I summarize some divergent thoughts during my research and literature reading:</p>

            <h3></h3>
            <ul>



            </ul>

            <h3></h3>
            <ul>




            </ul>
            <!-- You can write about questions you're pondering or your views on a societal phenomenon -->
        </section>
    </div>

    <footer>
        <p>&copy; 2025 ZOU CHENGQI Kay. All rights reserved.</p>
        <p>Back to <a href="my_page.html">Main Page</a></p>
    </footer>
</body>
</html>
